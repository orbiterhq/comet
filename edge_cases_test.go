package comet

// Edge case tests for production scenarios and error conditions.
// These tests verify robustness under stress, corruption, and resource limits.

import (
	"bytes"
	"context"
	"encoding/binary"
	"encoding/json"
	"fmt"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"testing"
	"time"
)

// ===== Tests from original edge_cases_test.go =====

// TestConcurrentRotationStorm tests concurrent rotation coordination to ensure
// no crashes or critical errors occur when multiple workers trigger rotation simultaneously
func TestConcurrentRotationStorm(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 2
	config.Storage.MaxFileSize = 1 << 16         // Small files to trigger rotation quickly (64KB)
	config.Compression.MinCompressSize = 1 << 30 // Disable compression for predictable sizing
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	// Use a unique shard ID to avoid conflicts with other tests
	// Use timestamp-based ID to ensure uniqueness across test runs
	shardID := uint32(time.Now().UnixNano() % 10000) // Random shard ID based on timestamp
	streamName := fmt.Sprintf("storm:v1:shard:%04d", shardID)

	// Create data that will trigger rotation after a few writes
	largeData := make([]byte, 10000) // 10KB entries
	for i := range largeData {
		largeData[i] = byte(i % 256)
	}

	// Launch many concurrent writers to stress the rotation logic
	const numWorkers = 20
	const writesPerWorker = 10

	var wg sync.WaitGroup
	errors := make(chan error, numWorkers*writesPerWorker)

	for worker := 0; worker < numWorkers; worker++ {
		wg.Add(1)
		go func(workerID int) {
			defer wg.Done()

			for i := 0; i < writesPerWorker; i++ {
				// Add worker ID to make data unique
				data := append(largeData, byte(workerID), byte(i))
				_, err := client.Append(ctx, streamName, [][]byte{data})
				if err != nil {
					errors <- fmt.Errorf("worker %d write %d failed: %w", workerID, i, err)
					return
				}
			}
		}(worker)
	}

	wg.Wait()
	close(errors)

	// The main goal is to ensure no crashes during concurrent rotation
	// Some "rotation needed" errors are expected and handled by the client
	criticalErrors := 0
	for err := range errors {
		// "rotation needed" errors are expected in multi-process mode and are handled by retry
		if !strings.Contains(err.Error(), "rotation needed") && !strings.Contains(err.Error(), "failed write: rotation needed") {
			t.Errorf("Critical concurrent write error: %v", err)
			criticalErrors++
		}
	}

	// Verify we have at least some data and files created
	parsedShardID, _ := parseShardFromStream(streamName)
	shard, _ := client.getOrCreateShard(parsedShardID)

	shard.mu.RLock()
	fileCount := len(shard.index.Files)
	shard.mu.RUnlock()

	if fileCount < 1 {
		t.Errorf("Expected at least 1 file, got %d", fileCount)
	}

	if criticalErrors > 0 {
		t.Errorf("Got %d critical errors during concurrent rotation test", criticalErrors)
	}

	t.Logf("Successfully completed concurrent rotation stress test with %d files and %d critical errors",
		fileCount, criticalErrors)
}

// TestPartialWriteRecovery tests that the system handles truncated files gracefully
// Note: This test documents current behavior - truncated files cause read errors
func TestPartialWriteRecovery(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Storage.MaxFileSize = 1 << 20 // 1MB files
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}

	ctx := context.Background()
	streamName := "recovery:v1:shard:0000"

	// Write some valid entries
	validData := []byte(`{"valid": "entry", "id": 1}`)
	_, err = client.Append(ctx, streamName, [][]byte{validData, validData, validData})
	if err != nil {
		t.Fatalf("failed to write valid entries: %v", err)
	}

	// Force sync to disk
	if err := client.Sync(ctx); err != nil {
		t.Fatalf("failed to sync: %v", err)
	}

	client.Close()

	// Simulate partial write corruption by truncating the data file
	shardID, _ := parseShardFromStream(streamName)
	shardDir := filepath.Join(dir, fmt.Sprintf("shard-%04d", shardID))

	// Find the data file
	files, err := os.ReadDir(shardDir)
	if err != nil {
		t.Fatalf("failed to read shard dir: %v", err)
	}

	var dataFile string
	for _, file := range files {
		if filepath.Ext(file.Name()) == ".comet" {
			dataFile = filepath.Join(shardDir, file.Name())
			break
		}
	}

	if dataFile == "" {
		t.Fatalf("no data file found")
	}

	// Get file info and truncate it slightly (corrupt last entry)
	info, err := os.Stat(dataFile)
	if err != nil {
		t.Fatalf("failed to stat data file: %v", err)
	}

	// Truncate to remove part of the last entry
	newSize := info.Size() - 10 // Remove 10 bytes
	if err := os.Truncate(dataFile, newSize); err != nil {
		t.Fatalf("failed to truncate file: %v", err)
	}

	// Reopen client - it should recover gracefully
	config2 := DefaultCometConfig()
	config2.Concurrency.ProcessCount = 0
	client2, err := NewClientWithConfig(dir, config2)
	if err != nil {
		t.Fatalf("failed to create client after corruption: %v", err)
	}
	defer client2.Close()

	// Try to read - this will currently fail due to truncation
	consumer := NewConsumer(client2, ConsumerOptions{
		Group: "recovery-test",
	})
	defer consumer.Close()

	messages, err := consumer.Read(ctx, []uint32{shardID}, 10)
	if err != nil {
		// This is expected behavior - truncated files cause read errors
		t.Logf("Expected error reading truncated file: %v", err)

		// Should still be able to write new entries after corruption
		newData := []byte(`{"recovered": true}`)
		_, err = client2.Append(ctx, streamName, [][]byte{newData})
		if err != nil {
			t.Errorf("failed to write after corruption: %v", err)
		} else {
			t.Logf("Successfully wrote new entry after corruption")
		}
		return
	}

	// If we somehow read successfully, that's also fine
	t.Logf("Unexpectedly recovered %d messages from truncated file", len(messages))

	// Should be able to write new entries after recovery
	newData := []byte(`{"recovered": true}`)
	_, err = client2.Append(ctx, streamName, [][]byte{newData})
	if err != nil {
		t.Errorf("failed to write after recovery: %v", err)
	}

	t.Logf("Successfully recovered from corruption, read %d valid entries", len(messages))
}

// TestIndexReconstructionWithGaps tests basic recovery when index is missing
// Note: This test documents current behavior - index reconstruction is limited
func TestIndexReconstructionWithGaps(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Indexing.BoundaryInterval = 5 // Index every 5 entries for testing
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}

	ctx := context.Background()
	streamName := "reconstruct:v1:shard:0000"

	// Write entries to create index
	const numEntries = 20
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"entry": %d}`, i))
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to write entry %d: %v", i, err)
		}
	}

	// Force checkpoint to save index
	if err := client.Sync(ctx); err != nil {
		t.Fatalf("failed to sync: %v", err)
	}

	client.Close()

	// Delete the index file to force reconstruction
	shardID, _ := parseShardFromStream(streamName)
	shardDir := filepath.Join(dir, fmt.Sprintf("shard-%04d", shardID))
	indexFile := filepath.Join(shardDir, "index.bin")

	if err := os.Remove(indexFile); err != nil {
		t.Fatalf("failed to remove index file: %v", err)
	}

	// Reopen client - should reconstruct index from data files
	config2 := DefaultCometConfig()
	config2.Concurrency.ProcessCount = 0
	config2.Indexing.BoundaryInterval = 5
	client2, err := NewClientWithConfig(dir, config2)
	if err != nil {
		t.Fatalf("failed to create client after index deletion: %v", err)
	}
	defer client2.Close()

	// Try to read entries after index deletion
	consumer := NewConsumer(client2, ConsumerOptions{
		Group: "reconstruct-test",
	})
	defer consumer.Close()

	messages, err := consumer.Read(ctx, []uint32{shardID}, numEntries)
	if err != nil {
		t.Logf("Reading failed after index deletion (expected): %v", err)
	} else {
		t.Logf("Successfully read %d entries after index deletion", len(messages))
	}

	// Verify we can still get basic info about the shard
	shard, _ := client2.getOrCreateShard(shardID)
	shard.mu.RLock()
	indexNodes := len(shard.index.BinaryIndex.Nodes)
	totalEntries := shard.index.CurrentEntryNumber
	shard.mu.RUnlock()

	t.Logf("After index deletion: %d total entries, %d index nodes", totalEntries, indexNodes)

	// Verify we can still write after reconstruction
	newData := []byte(`{"reconstructed": true}`)
	_, err = client2.Append(ctx, streamName, [][]byte{newData})
	if err != nil {
		t.Errorf("failed to write after reconstruction: %v", err)
	}

	t.Logf("Client recovered from index deletion and can accept new writes")
}

// TestConsumerOffsetDurability tests that consumer offsets survive crashes
func TestConsumerOffsetDurability(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Storage.CheckpointTime = 1 // Checkpoint every 1ms (effectively after every write)
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}

	ctx := context.Background()
	streamName := "durable:v1:shard:0000"
	consumerGroup := "durable-test"

	// Write some entries
	const numEntries = 10
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"message": %d}`, i))
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to write entry %d: %v", i, err)
		}
	}

	// Create consumer and read some entries
	consumer := NewConsumer(client, ConsumerOptions{
		Group: consumerGroup,
	})

	shardID, _ := parseShardFromStream(streamName)
	messages, err := consumer.Read(ctx, []uint32{shardID}, 5) // Read first 5
	if err != nil {
		t.Fatalf("failed to read entries: %v", err)
	}

	if len(messages) != 5 {
		t.Fatalf("expected 5 messages, got %d", len(messages))
	}

	// Acknowledge the first 3 messages
	var ackedIDs []MessageID
	for i := 0; i < 3; i++ {
		ackedIDs = append(ackedIDs, messages[i].ID)
	}

	if err := consumer.Ack(ctx, ackedIDs...); err != nil {
		t.Fatalf("failed to ack messages: %v", err)
	}

	// Force sync to persist offsets
	if err := client.Sync(ctx); err != nil {
		t.Fatalf("failed to sync: %v", err)
	}

	consumer.Close()
	client.Close()

	// Simulate crash/restart - reopen client
	config2 := DefaultCometConfig()
	config2.Concurrency.ProcessCount = 0
	client2, err := NewClientWithConfig(dir, config2)
	if err != nil {
		t.Fatalf("failed to reopen client: %v", err)
	}
	defer client2.Close()

	// Create new consumer with same group
	consumer2 := NewConsumer(client2, ConsumerOptions{
		Group: consumerGroup,
	})
	defer consumer2.Close()

	// Should start reading from where we left off (after the 3 acked messages)
	messages2, err := consumer2.Read(ctx, []uint32{shardID}, 10)
	if err != nil {
		t.Fatalf("failed to read after restart: %v", err)
	}

	// Should get the remaining entries (2 unacked + 5 new = 7 total)
	expectedRemaining := numEntries - 3 // Total minus the 3 we acked
	if len(messages2) != expectedRemaining {
		t.Errorf("Expected %d remaining messages after restart, got %d", expectedRemaining, len(messages2))
	}

	// First message should be the 4th original message (index 3)
	if len(messages2) > 0 && messages2[0].ID.EntryNumber != 3 {
		t.Errorf("Expected first message to be entry 3, got entry %d", messages2[0].ID.EntryNumber)
	}

	t.Logf("Successfully restored consumer offset: skipped %d acked messages, got %d remaining",
		3, len(messages2))
}

// TestMaxIndexEntriesEnforcement tests that index memory limits are enforced
func TestMaxIndexEntriesEnforcement(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Indexing.BoundaryInterval = 1 // Index every entry
	config.Indexing.MaxIndexEntries = 10 // Very small limit for testing
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "bounded:v1:shard:0000"

	// Write more entries than the index limit
	const numEntries = 25 // More than MaxIndexEntries
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"entry": %d}`, i))
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to write entry %d: %v", i, err)
		}
	}

	// Check that index is bounded
	shardID, _ := parseShardFromStream(streamName)
	shard, _ := client.getOrCreateShard(shardID)

	shard.mu.RLock()
	indexNodes := len(shard.index.BinaryIndex.Nodes)
	shard.mu.RUnlock()

	if indexNodes > 10 {
		t.Errorf("Expected index to be bounded to 10 entries, got %d", indexNodes)
	}

	// Should still be able to read all entries (index pruning shouldn't affect reads)
	consumer := NewConsumer(client, ConsumerOptions{
		Group: "bounded-test",
	})
	defer consumer.Close()

	messages, err := consumer.Read(ctx, []uint32{shardID}, numEntries)
	if err != nil {
		t.Fatalf("failed to read entries: %v", err)
	}

	if len(messages) != numEntries {
		t.Errorf("Expected to read %d entries despite index pruning, got %d", numEntries, len(messages))
	}

	t.Logf("Successfully enforced index limit: %d entries written, %d index nodes kept",
		numEntries, indexNodes)
}

// ===== Tests from critical_bugs_test.go =====

// TestReaderStalenessAfterFileRotation demonstrates that readers correctly
// detect when files have changed (either through rotation or deletion)
func TestReaderStalenessAfterFileRotation(t *testing.T) {
	dir := t.TempDir()

	// Create config with small files to trigger multiple rotations
	config := DefaultCometConfig()
	config.Storage.MaxFileSize = 1024 // 1KB files

	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write data to create initial files
	largeEntry := make([]byte, 500) // Half a file
	for i := 0; i < 5; i++ {
		_, err := client.Append(ctx, stream, [][]byte{largeEntry})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Create a consumer to get a reader
	consumer := NewConsumer(client, ConsumerOptions{Group: "test"})

	// Read some entries to establish a reader
	messages, err := consumer.Read(ctx, []uint32{0}, 1)
	if err != nil {
		t.Fatal(err)
	}
	if len(messages) != 1 {
		t.Fatalf("expected 1 message, got %d", len(messages))
	}

	// Get the reader reference
	shard, _ := client.getOrCreateShard(0)
	reader, err := consumer.getOrCreateReader(shard)
	if err != nil {
		t.Fatal(err)
	}

	// Check initial file count
	shard.mu.RLock()
	initialShardFiles := len(shard.index.Files)
	shard.mu.RUnlock()

	t.Logf("Initial state: shard has %d files", initialShardFiles)

	// Manually delete the first file to simulate retention
	shard.mu.Lock()
	firstFile := shard.index.Files[0].Path
	// Remove first file from index
	shard.index.Files = shard.index.Files[1:]
	shard.persistIndex()
	shard.mu.Unlock()

	// Actually delete the file
	os.Remove(firstFile)

	// Check file count after deletion
	shard.mu.RLock()
	afterDeletionFiles := len(shard.index.Files)
	shard.mu.RUnlock()

	t.Logf("After deletion: shard has %d files (was %d)", afterDeletionFiles, initialShardFiles)

	// Now try to read with the potentially stale reader
	// Our fix should detect that files have changed and try to recreate the reader
	reader2, err := consumer.getOrCreateReader(shard)

	// We expect this to fail because we manually deleted a file without proper cleanup
	// This demonstrates that our fix correctly detects file changes
	if err != nil {
		t.Log("SUCCESS: Reader creation failed as expected after detecting file mismatch:", err)
		// This proves our fix is working - it detected the files changed
		return
	}

	// With the new Reader architecture, file management is automatic and resilient
	// The reader should handle file deletions gracefully by updating its internal state
	if reader2 == reader {
		t.Log("SUCCESS: Reader maintained consistency after file deletion - file management is automatic")
	} else {
		t.Log("Reader was recreated after file deletion - also valid behavior")
	}

	// Verify the reader's file list was updated to match the shard
	// With the new architecture, this should work transparently
	t.Logf("Reader successfully updated after file deletion - file management is now automatic")

	// Verify we can still read data
	messages2, err := consumer.Read(ctx, []uint32{0}, 1)
	if err != nil {
		t.Fatal("Failed to read after file deletion:", err)
	}
	if len(messages2) != 1 {
		t.Fatalf("Expected 1 message after deletion, got %d", len(messages2))
	}
}

// TestCrashRecoveryFileEntries demonstrates the bug where crash recovery
// doesn't update the file's entry count
func TestCrashRecoveryFileEntries(t *testing.T) {
	dir := t.TempDir()

	config := DefaultCometConfig()
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write some entries
	for i := 0; i < 5; i++ {
		_, err := client.Append(ctx, stream, [][]byte{[]byte(fmt.Sprintf("entry-%d", i))})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Get the shard
	shard, _ := client.getOrCreateShard(0)

	// Force a checkpoint to save index
	shard.mu.Lock()
	shard.persistIndex()
	originalEntries := shard.index.Files[0].Entries
	shard.mu.Unlock()

	t.Logf("Original file entries: %d", originalEntries)

	// Simulate a crash by directly writing to the file without updating index
	shard.writeMu.Lock()
	crashEntry := []byte("crash-entry")
	header := make([]byte, headerSize)
	binary.LittleEndian.PutUint32(header[0:4], uint32(len(crashEntry)))
	binary.LittleEndian.PutUint64(header[4:12], uint64(time.Now().UnixNano()))

	shard.writer.Write(header)
	shard.writer.Write(crashEntry)
	shard.writer.Flush()
	shard.writeMu.Unlock()

	// Close and reopen to trigger recovery
	client.Close()

	client2, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client2.Close()

	// Check if recovery updated the file entry count
	shard2, _ := client2.getOrCreateShard(0)
	shard2.mu.RLock()
	recoveredEntries := shard2.index.Files[0].Entries
	recoveredTotalEntries := shard2.index.CurrentEntryNumber
	shard2.mu.RUnlock()

	t.Logf("After recovery: file entries=%d, total entries=%d", recoveredEntries, recoveredTotalEntries)

	// The bug: file entries won't include the crash entry
	if recoveredEntries == originalEntries {
		t.Error("BUG CONFIRMED: Crash recovery didn't update file entry count")
		t.Errorf("File still shows %d entries but should have %d", recoveredEntries, originalEntries+1)
	}

	// But total entries will be updated
	if recoveredTotalEntries == originalEntries+1 {
		t.Log("Total entries were correctly updated to", recoveredTotalEntries)
	}
}

// TestFileGrowthRaceCondition verifies that the retry logic in ReadEntryAtPosition
// correctly handles the temporary race condition between index updates and file growth
func TestFileGrowthRaceCondition(t *testing.T) {
	dir := t.TempDir()

	config := DefaultCometConfig()
	config.Retention.CleanupInterval = 0 // Disable retention

	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write initial data
	for i := 0; i < 5; i++ {
		_, err := client.Append(ctx, stream, [][]byte{
			[]byte(fmt.Sprintf("entry-%d", i)),
		})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Create consumer and establish reader
	consumer := NewConsumer(client, ConsumerOptions{Group: "test"})
	defer consumer.Close()

	// Read to establish the reader
	messages, err := consumer.Read(ctx, []uint32{0}, 1)
	if err != nil {
		t.Fatal(err)
	}
	for _, msg := range messages {
		consumer.Ack(ctx, msg.ID)
	}

	// Now write more data and immediately try to read it
	// This simulates the race condition where the index is updated
	// but the file hasn't been flushed yet
	errorSeen := false
	for i := 0; i < 10; i++ {
		// Write one entry
		_, err := client.Append(ctx, stream, [][]byte{
			[]byte(fmt.Sprintf("race-entry-%d", i)),
		})
		if err != nil {
			t.Fatal(err)
		}

		// Immediately try to read it (might hit the race)
		messages, err := consumer.Read(ctx, []uint32{0}, 1)
		if err != nil {
			if strings.Contains(err.Error(), "extends beyond file") ||
				strings.Contains(err.Error(), "invalid offset") {
				errorSeen = true
				t.Errorf("Hit race condition error: %v", err)
			}
		} else if len(messages) > 0 {
			// Successfully read the entry
			for _, msg := range messages {
				consumer.Ack(ctx, msg.ID)
			}
		}
	}

	if errorSeen {
		t.Error("Race condition was not handled by retry logic")
	} else {
		t.Log("Success: All entries read without race condition errors")
	}
}

// ===== Tests from file_boundary_test.go =====

// TestConsumerReadAcrossFileBoundaries verifies that consumers can correctly read entries
// that span multiple files, especially when entries are written at file rotation boundaries
func TestConsumerReadAcrossFileBoundaries(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Storage.MaxFileSize = 10 * 1024 // 10KB - more realistic but still forces multiple files
	config.Indexing.BoundaryInterval = 10
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "test:v1:shard:0000"

	// Write entries that will span multiple files
	const numEntries = 200
	entryData := make([]byte, 100) // Each entry ~100 bytes
	for i := range entryData {
		entryData[i] = 'A' + byte(i%26)
	}

	writtenIDs := make([]string, 0, numEntries)
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"id":%d,"data":"%s"}`, i, string(entryData)))
		ids, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to add entry %d: %v", i, err)
		}
		for _, id := range ids {
			writtenIDs = append(writtenIDs, id.String())
		}
	}

	// Force sync
	if err := client.Sync(ctx); err != nil {
		t.Fatalf("failed to sync: %v", err)
	}

	// Close and reopen client to ensure all data is persisted
	client.Close()

	client, err = NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to recreate client: %v", err)
	}
	defer client.Close()

	// Get shard to check file count
	shard, err := client.getOrCreateShard(0)
	if err != nil {
		t.Fatalf("failed to get shard: %v", err)
	}

	shard.mu.RLock()
	fileCount := len(shard.index.Files)
	currentEntryNum := shard.index.CurrentEntryNumber
	t.Logf("Created %d files for %d entries (CurrentEntryNumber: %d)", fileCount, numEntries, currentEntryNum)
	if fileCount < 2 {
		t.Errorf("expected multiple files, got %d", fileCount)
	}

	// Log file info - show ALL files to understand the structure
	t.Logf("=== File Structure ===")
	for i, file := range shard.index.Files {
		fileInfo, err := os.Stat(file.Path)
		var fileSize int64
		if err == nil {
			fileSize = fileInfo.Size()
		}
		t.Logf("File[%d]: entries=%d, startEntry=%d, endOffset=%d, size=%d bytes, path=%s",
			i, file.Entries, file.StartEntry, file.EndOffset, fileSize, filepath.Base(file.Path))

	}

	// Log binary index nodes for debugging
	for _, node := range shard.index.BinaryIndex.Nodes {
		if node.EntryNumber%10 == 0 || node.EntryNumber == 0 || node.EntryNumber >= int64(numEntries-2) {
			t.Logf("Entry %d at file %d, offset %d", node.EntryNumber, node.Position.FileIndex, node.Position.ByteOffset)
		}
	}
	shard.mu.RUnlock()

	// Create consumer and read all entries
	consumer := NewConsumer(client, ConsumerOptions{
		Group: "test",
	})
	defer consumer.Close()

	// Read all entries and verify
	totalRead := 0
	readIDs := make([]string, 0, numEntries)

	for totalRead < numEntries {
		// Read smaller batches near the end to isolate the issue
		batchSize := 10
		if totalRead >= numEntries-20 {
			batchSize = 1
			t.Logf("Reading entry %d (single entry mode)", totalRead)
		}
		messages, err := consumer.Read(ctx, []uint32{0}, batchSize)
		if err != nil {
			// Log current consumer state before failing
			shard.mu.RLock()
			consumerOffset := shard.index.ConsumerOffsets[consumer.group]
			t.Logf("Consumer offset: %d, CurrentEntryNumber: %d", consumerOffset, shard.index.CurrentEntryNumber)
			shard.mu.RUnlock()
			t.Fatalf("failed to read entries at position %d: %v", totalRead, err)
		}

		if len(messages) == 0 {
			t.Fatalf("expected messages but got none at totalRead=%d", totalRead)
		}

		// Collect IDs and ack
		var messageIDs []MessageID
		for _, msg := range messages {
			readIDs = append(readIDs, msg.ID.String())
			messageIDs = append(messageIDs, msg.ID)

			// Verify data integrity
			var decoded map[string]interface{}
			if err := json.Unmarshal(msg.Data, &decoded); err != nil {
				t.Errorf("failed to decode message %s: %v", msg.ID, err)
			}
		}

		err = consumer.Ack(ctx, messageIDs...)
		if err != nil {
			t.Fatalf("failed to ack batch: %v", err)
		}

		totalRead += len(messages)
		t.Logf("Read %d messages, total: %d/%d", len(messages), totalRead, numEntries)
	}

	// Verify we read all entries in order
	if len(readIDs) != len(writtenIDs) {
		t.Errorf("expected to read %d entries, got %d", len(writtenIDs), len(readIDs))
	}

	for i, id := range readIDs {
		if id != writtenIDs[i] {
			t.Errorf("entry %d: expected ID %s, got %s", i, writtenIDs[i], id)
		}
	}

	// Verify lag is 0
	lag, err := consumer.GetLag(ctx, 1)
	if err != nil {
		t.Fatalf("failed to get lag: %v", err)
	}
	if lag != 0 {
		t.Errorf("expected lag 0, got %d", lag)
	}
}

// TestConsumerReadEntryAtFileBoundary specifically tests reading entries that are
// written exactly at file rotation boundaries
func TestConsumerReadEntryAtFileBoundary(t *testing.T) {
	t.Skip("Known issue: file rotation can create empty files that cause read failures")
	dir := t.TempDir()

	// Configure to rotate after exactly 3 entries (header + data size)
	// Header = 12 bytes, small data = ~30 bytes, so 3 entries = ~126 bytes
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Storage.MaxFileSize = 130     // Force rotation after 3 entries
	config.Indexing.BoundaryInterval = 1 // Store every entry position
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "test:v1:shard:0002"

	// Write entries one by one to control rotation points
	const numEntries = 10
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"id":%d}`, i))
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to add entry %d: %v", i, err)
		}

		// Force sync after each to ensure it's written
		if err := client.Sync(ctx); err != nil {
			t.Fatalf("failed to sync: %v", err)
		}
	}

	// Get shard to verify file structure
	shard, err := client.getOrCreateShard(2)
	if err != nil {
		t.Fatalf("failed to get shard: %v", err)
	}

	shard.mu.RLock()
	t.Logf("Created %d files for %d entries", len(shard.index.Files), numEntries)

	// Log all indexed positions
	for _, node := range shard.index.BinaryIndex.Nodes {
		t.Logf("Entry %d stored at file %d, offset %d", node.EntryNumber, node.Position.FileIndex, node.Position.ByteOffset)
	}
	shard.mu.RUnlock()

	// Create consumer and read specific entries that should be at boundaries
	consumer := NewConsumer(client, ConsumerOptions{
		Group: "boundary-test",
	})
	defer consumer.Close()

	// Give the reader time to map all files
	time.Sleep(100 * time.Millisecond)

	// Read entries one by one to test boundary conditions
	for i := 0; i < numEntries; i++ {
		messages, err := consumer.Read(ctx, []uint32{2}, 1)
		if err != nil {
			t.Fatalf("failed to read entry %d: %v", i, err)
		}

		if len(messages) != 1 {
			t.Fatalf("expected 1 message at position %d, got %d", i, len(messages))
		}

		// Verify it's the correct entry
		expectedID := fmt.Sprintf("2-%d", i)
		if messages[0].ID.String() != expectedID {
			t.Errorf("entry %d: expected ID %s, got %s", i, expectedID, messages[0].ID.String())
		}

		// Ack the entry
		err = consumer.Ack(ctx, messages[0].ID)
		if err != nil {
			t.Fatalf("failed to ack entry %d: %v", i, err)
		}
	}

	t.Log("Successfully read all entries across file boundaries")
}

// ===== Tests from index_limit_test.go =====

// TestIndexEntryLimit verifies that index entries are properly limited
func TestIndexEntryLimit(t *testing.T) {
	dir := t.TempDir()

	// Configure with a very low limit
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Indexing.BoundaryInterval = 5 // Store every 5th entry
	config.Indexing.MaxIndexEntries = 10 // Only keep 10 entries
	config.Storage.MaxFileSize = 1 << 20 // 1MB files
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "test:v1:shard:0000"

	// Write more entries than the limit
	const numEntries = 50
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"id":%d,"data":"test"}`, i))
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to add entry %d: %v", i, err)
		}
	}

	// Force sync
	if err := client.Sync(ctx); err != nil {
		t.Fatalf("failed to sync: %v", err)
	}

	// Get shard to check index size
	shard, err := client.getOrCreateShard(0)
	if err != nil {
		t.Fatalf("failed to get shard: %v", err)
	}

	shard.mu.RLock()
	binaryNodeCount := len(shard.index.BinaryIndex.Nodes)

	// Log what entries are in the index
	t.Logf("Binary index nodes: %d (limit: %d)", binaryNodeCount, client.config.Indexing.MaxIndexEntries)

	// Find min and max entries in binary index
	var minEntry, maxEntry int64 = numEntries, -1
	for _, node := range shard.index.BinaryIndex.Nodes {
		if node.EntryNumber < minEntry {
			minEntry = node.EntryNumber
		}
		if node.EntryNumber > maxEntry {
			maxEntry = node.EntryNumber
		}
	}
	t.Logf("Binary index entries range: %d to %d", minEntry, maxEntry)

	shard.mu.RUnlock()

	// Verify limits are respected
	if binaryNodeCount > client.config.Indexing.MaxIndexEntries {
		t.Errorf("binary index nodes exceed limit: got %d, want <= %d",
			binaryNodeCount, client.config.Indexing.MaxIndexEntries)
	}

	// Verify newer entries are kept (older ones pruned)
	if maxEntry < int64(numEntries-5) {
		t.Errorf("expected to keep recent entries, but max entry is %d (total: %d)",
			maxEntry, numEntries)
	}
}

// TestBinaryIndexPruning verifies binary index pruning works correctly
func TestBinaryIndexPruning(t *testing.T) {
	var bi BinarySearchableIndex
	bi.IndexInterval = 1 // Index every entry
	bi.MaxNodes = 5      // Keep only 5 nodes

	// Add more nodes than the limit
	for i := int64(0); i < 20; i++ {
		bi.AddIndexNode(i, EntryPosition{FileIndex: 0, ByteOffset: i * 100})
	}

	// Verify we only have MaxNodes entries
	if len(bi.Nodes) != bi.MaxNodes {
		t.Errorf("expected %d nodes, got %d", bi.MaxNodes, len(bi.Nodes))
	}

	// Verify we kept the most recent entries (15-19)
	expectedStart := int64(15)
	for i, node := range bi.Nodes {
		expected := expectedStart + int64(i)
		if node.EntryNumber != expected {
			t.Errorf("node %d: expected entry %d, got %d", i, expected, node.EntryNumber)
		}
	}
}

// TestIndexLimitWithConsumer verifies consumers still work with limited index
func TestIndexLimitWithConsumer(t *testing.T) {
	dir := t.TempDir()

	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Indexing.BoundaryInterval = 5 // Store every 5th entry
	config.Indexing.MaxIndexEntries = 20 // Keep 20 boundary entries
	config.Storage.MaxFileSize = 1 << 20 // 1MB files
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "test:v1:shard:0003"

	// Write entries
	const numEntries = 100
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf(`{"id":%d}`, i))
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to add entry %d: %v", i, err)
		}
	}

	// Force sync
	if err := client.Sync(ctx); err != nil {
		t.Fatalf("failed to sync: %v", err)
	}

	// Create consumer and try to read all entries
	consumer := NewConsumer(client, ConsumerOptions{
		Group: "test",
	})
	defer consumer.Close()

	// Read all entries - should work even with limited index
	totalRead := 0
	for totalRead < numEntries {
		messages, err := consumer.Read(ctx, []uint32{3}, 10)
		if err != nil {
			t.Fatalf("failed to read entries at position %d: %v", totalRead, err)
		}

		if len(messages) == 0 {
			t.Fatalf("expected messages but got none at totalRead=%d", totalRead)
		}

		// Ack messages
		var messageIDs []MessageID
		for _, msg := range messages {
			messageIDs = append(messageIDs, msg.ID)
		}

		err = consumer.Ack(ctx, messageIDs...)
		if err != nil {
			t.Fatalf("failed to ack batch: %v", err)
		}

		totalRead += len(messages)
	}

	if totalRead != numEntries {
		t.Errorf("expected to read %d entries, got %d", numEntries, totalRead)
	}

	t.Log("Successfully read all entries with limited index")
}

// ===== Tests from io_outside_lock_test.go =====

// TestIO_OutsideLock verifies that I/O happens outside the critical section
func TestIO_OutsideLock(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0      // Single writer test
	config.Compression.MinCompressSize = 100 // Enable compression for some entries
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "test:v1:shard:0000"

	// Track lock hold times
	_ = time.Now() // Placeholder for timing tracking

	// This test verifies that I/O happens outside locks
	// With our simplified implementation using bufio.Writer,
	// the actual disk I/O happens during Flush() which we
	// explicitly do outside the critical section

	// Create a large entry to make I/O measurable
	largeData := make([]byte, 1<<20) // 1MB
	for i := range largeData {
		largeData[i] = byte(i % 256)
	}

	// Measure timing
	start := time.Now()
	_, err = client.Append(ctx, streamName, [][]byte{largeData})
	if err != nil {
		t.Fatalf("failed to add entry: %v", err)
	}
	totalTime := time.Since(start)

	t.Logf("Total operation time: %v", totalTime)
	t.Logf("Data size: %d bytes", len(largeData))

	// The key insight: with I/O outside lock, lock hold time should be minimal
	// even for large writes. We can't directly measure this in the test,
	// but the restructured code ensures I/O happens outside the critical section.
}

// BenchmarkLockContention compares lock hold time with different optimizations
func BenchmarkLockContention(b *testing.B) {
	scenarios := []struct {
		name              string
		enableCompression bool
		dataSize          int
	}{
		{"small_uncompressed", false, 100},
		{"large_uncompressed", false, 1 << 20}, // 1MB
		{"large_compressed", true, 1 << 20},    // 1MB
	}

	for _, scenario := range scenarios {
		b.Run(scenario.name, func(b *testing.B) {
			dir := b.TempDir()

			config := DefaultCometConfig()
			config.Concurrency.ProcessCount = 2
			config.Compression.MinCompressSize = 1 << 30 // Disable compression by default

			if scenario.enableCompression {
				config.Compression.MinCompressSize = 1000 // Enable for large entries
			}

			client, err := NewClientWithConfig(dir, config)
			if err != nil {
				b.Fatalf("failed to create client: %v", err)
			}
			defer client.Close()

			ctx := context.Background()
			streamName := "bench:v1:shard:0000"

			// Create test data
			data := make([]byte, scenario.dataSize)
			for i := range data {
				data[i] = byte(i % 256)
			}

			b.ResetTimer()
			b.ReportAllocs()

			// Run writes in parallel to measure contention
			var wg sync.WaitGroup
			for i := 0; i < b.N; i++ {
				wg.Add(1)
				go func() {
					defer wg.Done()
					_, err := client.Append(ctx, streamName, [][]byte{data})
					if err != nil {
						b.Errorf("failed to add entry: %v", err)
					}
				}()
			}
			wg.Wait()

			b.ReportMetric(float64(scenario.dataSize), "bytes_per_write")
		})
	}
}

// TestOptimizationShowcase demonstrates all three optimizations working together
func TestOptimizationShowcase(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 2
	config.Compression.MinCompressSize = 1000
	config.Indexing.BoundaryInterval = 10 // Frequent indexing for binary search demo
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()

	// 1. Demonstrate compression outside lock
	t.Run("compression_outside_lock", func(t *testing.T) {
		streamName := "demo:v1:shard:0000"

		// Large compressible data
		data := []byte(fmt.Sprintf(`{"message": "%s"}`, string(make([]byte, 10000))))

		start := time.Now()
		_, err := client.Append(ctx, streamName, [][]byte{data})
		if err != nil {
			t.Fatalf("failed to add: %v", err)
		}
		elapsed := time.Since(start)

		t.Logf("Write with compression (outside lock): %v", elapsed)
	})

	// 2. Demonstrate batch acknowledgments
	t.Run("batch_acknowledgments", func(t *testing.T) {
		consumer := NewConsumer(client, ConsumerOptions{
			Group: "test",
		})
		defer consumer.Close()

		// Create multiple shards with data
		var allMessageIDs []MessageID
		for shard := uint32(0); shard < 4; shard++ {
			streamName := fmt.Sprintf("demo:v1:shard:%04d", shard+10)

			// Add some entries
			for i := 0; i < 10; i++ {
				data := []byte(fmt.Sprintf(`{"shard":%d,"seq":%d}`, shard, i))
				idList, _ := client.Append(ctx, streamName, [][]byte{data})
				allMessageIDs = append(allMessageIDs, idList...)
			}
		}

		// Batch acknowledge across all shards
		start := time.Now()
		err := consumer.Ack(ctx, allMessageIDs...)
		if err != nil {
			t.Fatalf("batch ack failed: %v", err)
		}
		elapsed := time.Since(start)

		t.Logf("Batch acknowledged %d messages across 4 shards in %v", len(allMessageIDs), elapsed)
	})

	// 3. Demonstrate binary searchable index
	t.Run("binary_searchable_index", func(t *testing.T) {
		streamName := "demo:v1:shard:0020"

		// Add many entries
		for i := 0; i < 100; i++ {
			data := []byte(fmt.Sprintf(`{"seq":%d}`, i))
			_, err := client.Append(ctx, streamName, [][]byte{data})
			if err != nil {
				t.Fatalf("failed to add: %v", err)
			}
		}

		// Get shard and check index
		shardID, _ := parseShardFromStream(streamName)
		shard, _ := client.getOrCreateShard(shardID)

		shard.mu.RLock()
		indexNodeCount := len(shard.index.BinaryIndex.Nodes)
		shard.mu.RUnlock()

		t.Logf("Created %d binary index nodes for 100 entries", indexNodeCount)
		t.Logf("Binary search provides O(log n) = O(log %d) â‰ˆ %d comparisons for lookups",
			indexNodeCount, int(float64(indexNodeCount)/float64(2)))
	})
}

// TestCorruptedIndexFileRecovery tests that the system can recover from a corrupted index file
func TestCorruptedIndexFileRecovery(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Concurrency.ProcessCount = 0
	config.Indexing.BoundaryInterval = 5

	// Create client and write some data
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write entries
	for i := 0; i < 20; i++ {
		_, err := client.Append(ctx, stream, [][]byte{[]byte(fmt.Sprintf("entry-%d", i))})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Force index persistence
	shard, _ := client.getOrCreateShard(0)
	shard.mu.Lock()
	shard.persistIndex()
	shard.mu.Unlock()

	client.Close()

	// Corrupt the index file
	indexPath := filepath.Join(dir, "shard-0000", "index.bin")
	data, err := os.ReadFile(indexPath)
	if err != nil {
		t.Fatal(err)
	}

	// Write garbage in the middle of the file
	if len(data) > 100 {
		copy(data[50:100], bytes.Repeat([]byte{0xFF}, 50))
	}

	err = os.WriteFile(indexPath, data, 0644)
	if err != nil {
		t.Fatal(err)
	}

	// Try to reopen - should handle corruption gracefully
	client2, err := NewClientWithConfig(dir, config)
	if err != nil {
		// Some corruptions might be caught at open time
		t.Logf("Client creation failed with corrupted index (expected): %v", err)
		return
	}
	defer client2.Close()

	// Should still be able to write new data
	_, err = client2.Append(ctx, stream, [][]byte{[]byte("after-corruption")})
	if err != nil {
		t.Fatalf("Failed to write after index corruption: %v", err)
	}

	t.Log("Successfully recovered from corrupted index file")
}

// TestWritePathPanicRecovery tests that panics in the write path don't crash the process
func TestWritePathPanicRecovery(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write some normal data first
	_, err = client.Append(ctx, stream, [][]byte{[]byte("normal-entry")})
	if err != nil {
		t.Fatal(err)
	}

	// Test that extremely large data doesn't panic
	hugeData := make([]byte, 100*1024*1024) // 100MB
	_, err = client.Append(ctx, stream, [][]byte{hugeData})
	if err == nil {
		t.Log("Successfully handled huge data without panic")
	} else {
		t.Logf("Huge data rejected with error: %v", err)
	}

	// Should still be able to write after potential panic
	_, err = client.Append(ctx, stream, [][]byte{[]byte("after-huge-write")})
	if err != nil {
		t.Fatalf("Failed to write after huge data attempt: %v", err)
	}

	t.Log("Write path properly handles edge cases without panicking")
}

// TestMmapExhaustion tests behavior when too many files are memory-mapped
func TestMmapExhaustion(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Storage.MaxFileSize = 1024 // Very small files to create many of them
	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()

	// Create many shards with data to force many mmap operations
	const numShards = 100
	for i := 0; i < numShards; i++ {
		stream := fmt.Sprintf("test:v1:shard:%04d", i)
		_, err := client.Append(ctx, stream, [][]byte{[]byte(fmt.Sprintf("shard-%d", i))})
		if err != nil {
			// Log but don't fail - we're testing limits
			t.Logf("Failed to write to shard %d: %v", i, err)
			break
		}
	}

	// Now try to read from all shards simultaneously
	readers := make([]*Reader, 0, numShards)
	for i := 0; i < numShards; i++ {
		shard, err := client.getOrCreateShard(uint32(i))
		if err != nil {
			continue
		}

		shard.mu.RLock()
		if len(shard.index.Files) > 0 {
			reader, err := NewReader(uint32(i), shard.index)
			if err != nil {
				t.Logf("Failed to create reader for shard %d: %v", i, err)
			} else {
				readers = append(readers, reader)
			}
		}
		shard.mu.RUnlock()
	}

	t.Logf("Successfully created %d readers out of %d shards", len(readers), numShards)

	// Clean up readers
	for _, r := range readers {
		r.Close()
	}

	// System should still be functional
	_, err = client.Append(ctx, "test:v1:shard:0000", [][]byte{[]byte("after-mmap-test")})
	if err != nil {
		t.Fatalf("Failed to write after mmap exhaustion test: %v", err)
	}

	t.Log("System handles mmap exhaustion gracefully")
}

// TestConsumerGroupSplitBrain tests that multiple consumers in the same group coordinate properly
func TestConsumerGroupSplitBrain(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Storage.CheckpointTime = 1 // Fast checkpointing

	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write test messages
	const numMessages = 10
	for i := 0; i < numMessages; i++ {
		_, err := client.Append(ctx, stream, [][]byte{[]byte(fmt.Sprintf("msg-%d", i))})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Create a consumer and process some messages
	consumer1 := NewConsumer(client, ConsumerOptions{Group: "shared-group"})
	defer consumer1.Close()

	var processedCount int
	var mu sync.Mutex
	ctx1, cancel1 := context.WithTimeout(ctx, 100*time.Millisecond)
	defer cancel1()

	go consumer1.Process(ctx1, func(ctx context.Context, messages []StreamMessage) error {
		mu.Lock()
		processedCount += len(messages)
		mu.Unlock()
		return nil
	}, WithStream("test:v1:shard:*"), WithBatchSize(2))

	<-ctx1.Done()

	// Create second consumer in same group - should start from where first left off
	consumer2 := NewConsumer(client, ConsumerOptions{Group: "shared-group"})
	defer consumer2.Close()

	var secondProcessed int
	ctx2, cancel2 := context.WithTimeout(ctx, 100*time.Millisecond)
	defer cancel2()

	go consumer2.Process(ctx2, func(ctx context.Context, messages []StreamMessage) error {
		mu.Lock()
		secondProcessed += len(messages)
		mu.Unlock()
		return nil
	}, WithStream("test:v1:shard:*"), WithBatchSize(2))

	<-ctx2.Done()

	mu.Lock()
	t.Logf("First consumer processed %d messages", processedCount)
	t.Logf("Second consumer processed %d messages", secondProcessed)
	mu.Unlock()
	t.Logf("Total: %d out of %d", processedCount+secondProcessed, numMessages)

	// Basic sanity check - both consumers together shouldn't process more than total
	if processedCount+secondProcessed > numMessages {
		t.Errorf("Processed more messages than written! Got %d, expected max %d",
			processedCount+secondProcessed, numMessages)
	}
}

// TestRetentionDataIntegrity tests that retention works correctly and our fix prevents race conditions
func TestRetentionDataIntegrity(t *testing.T) {
	dir := t.TempDir()

	// Use same config as the working retention test
	config := DefaultCometConfig()
	config.Retention.MaxAge = 200 * time.Millisecond
	config.Retention.CleanupInterval = 100 * time.Millisecond
	config.Retention.MinFilesToKeep = 1

	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatalf("failed to create client: %v", err)
	}
	defer client.Close()

	ctx := context.Background()
	streamName := "events:v1:shard:0000"

	// Write some data
	for i := 0; i < 10; i++ {
		data := [][]byte{[]byte(fmt.Sprintf(`{"id": %d}`, i))}
		_, err := client.Append(ctx, streamName, data)
		if err != nil {
			t.Fatalf("failed to add data: %v", err)
		}
	}

	// Get shard to manually create old files
	shard, err := client.getOrCreateShard(0)
	if err != nil {
		t.Fatalf("failed to get shard: %v", err)
	}

	// Check initial state
	shard.mu.RLock()
	initialFileCount := len(shard.index.Files)
	shard.mu.RUnlock()
	t.Logf("Initial file count: %d", initialFileCount)

	// Manually mark the current file as old (same as working test)
	shard.mu.Lock()
	if len(shard.index.Files) > 0 {
		shard.index.Files[0].EndTime = time.Now().Add(-300 * time.Millisecond)
	}
	shard.mu.Unlock()

	// Wait for cleanup
	time.Sleep(300 * time.Millisecond)

	// Get retention stats
	stats := client.GetRetentionStats()
	t.Logf("Retention stats: %+v", stats)

	// The old file should have been cleaned up
	if int(stats.TotalFiles) > config.Retention.MinFilesToKeep {
		t.Errorf("expected at most %d files after cleanup, got %d", config.Retention.MinFilesToKeep, stats.TotalFiles)
	}

	// CRITICAL: Test our race condition fix by verifying we can still read
	// This is where the original bug would cause "file not found" errors
	consumer := NewConsumer(client, ConsumerOptions{Group: "integrity-test"})
	defer consumer.Close()

	messages, err := consumer.Read(ctx, []uint32{0}, 5)
	if err != nil {
		// This error would indicate our fix didn't work
		t.Errorf("RACE CONDITION: Failed to read after retention cleanup: %v", err)
	} else {
		t.Logf("SUCCESS: Read %d messages after retention cleanup", len(messages))
	}

	// Verify all files referenced in index actually exist on disk
	shard.mu.RLock()
	for _, file := range shard.index.Files {
		if _, err := os.Stat(file.Path); err != nil {
			t.Errorf("INTEGRITY ERROR: Index references non-existent file: %s (%v)", file.Path, err)
		}
	}
	shard.mu.RUnlock()

	t.Log("Retention system working correctly with race condition fix")
}

// TestFindEntryBinarySearch tests the binary search functionality for entry lookup
func TestFindEntryBinarySearch(t *testing.T) {
	dir := t.TempDir()
	config := DefaultCometConfig()
	config.Indexing.BoundaryInterval = 5 // Index every 5 entries

	client, err := NewClientWithConfig(dir, config)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write entries to build up the binary index
	const numEntries = 50
	for i := 0; i < numEntries; i++ {
		data := []byte(fmt.Sprintf("entry-%d", i))
		_, err := client.Append(ctx, stream, [][]byte{data})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Get the shard to test FindEntry directly
	shard, err := client.getOrCreateShard(0)
	if err != nil {
		t.Fatal(err)
	}

	shard.mu.RLock()
	// Test finding entries that should exist
	for i := int64(0); i < numEntries; i += 5 { // Test boundary entries
		pos, found := shard.index.BinaryIndex.FindEntry(i)
		if !found {
			t.Errorf("Expected to find entry %d, but not found", i)
		} else {
			t.Logf("Found entry %d at file %d, offset %d", i, pos.FileIndex, pos.ByteOffset)
		}
	}

	// Test finding entry that doesn't exist (beyond range)
	// FindEntry should return the last indexed entry for scan-forward lookup
	pos, found := shard.index.BinaryIndex.FindEntry(numEntries + 10)
	if !found {
		t.Errorf("Expected to find closest entry for %d for scan-forward", numEntries+10)
	} else {
		t.Logf("Entry %d not found, but got closest entry at file %d, offset %d for scan-forward",
			numEntries+10, pos.FileIndex, pos.ByteOffset)
	}

	// Test finding entry 0 when index exists
	pos, found = shard.index.BinaryIndex.FindEntry(0)
	if !found && len(shard.index.BinaryIndex.Nodes) > 0 {
		t.Errorf("Expected to find entry 0, but not found")
	}

	shard.mu.RUnlock()

	t.Logf("Binary index has %d nodes for %d entries",
		len(shard.index.BinaryIndex.Nodes), numEntries)
}

// TestAckRangeFunctionality tests batch acknowledgment functionality
func TestAckRangeFunctionality(t *testing.T) {
	dir := t.TempDir()
	client, err := NewClient(dir)
	if err != nil {
		t.Fatal(err)
	}
	defer client.Close()

	ctx := context.Background()
	stream := "test:v1:shard:0000"

	// Write test messages
	const numMessages = 20
	for i := 0; i < numMessages; i++ {
		_, err := client.Append(ctx, stream, [][]byte{[]byte(fmt.Sprintf("msg-%d", i))})
		if err != nil {
			t.Fatal(err)
		}
	}

	// Create consumer
	consumer := NewConsumer(client, ConsumerOptions{Group: "ack-range-test"})
	defer consumer.Close()

	// Read some messages
	messages, err := consumer.Read(ctx, []uint32{0}, 10)
	if err != nil {
		t.Fatal(err)
	}

	if len(messages) == 0 {
		t.Fatal("Expected to read some messages")
	}

	// Test AckRange with a range of entry numbers
	startEntry := messages[0].ID.EntryNumber
	endEntry := messages[len(messages)-1].ID.EntryNumber
	shardID := messages[0].ID.ShardID

	err = consumer.AckRange(ctx, shardID, startEntry, endEntry)
	if err != nil {
		t.Fatalf("AckRange failed: %v", err)
	}

	// Verify that subsequent reads don't return the acknowledged messages
	messages2, err := consumer.Read(ctx, []uint32{shardID}, 5)
	if err != nil {
		t.Fatal(err)
	}

	// Should start from after the acknowledged range
	if len(messages2) > 0 && messages2[0].ID.EntryNumber <= endEntry {
		t.Errorf("Expected next message to be after acknowledged range. Got entry %d, expected > %d",
			messages2[0].ID.EntryNumber, endEntry)
	}

	t.Logf("Successfully acknowledged range %d to %d on shard %d", startEntry, endEntry, shardID)
}
