name: Benchmarks
on:
  push:
    branches: [main]
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - '.mise.toml'
      - '.github/workflows/benchmark.yml'
  pull_request:
    branches: [main]
    paths:
      - '**.go'
      - 'go.mod'
      - 'go.sum'
      - '.mise.toml'
      - '.github/workflows/benchmark.yml'
permissions:
  contents: read
  pull-requests: write
  issues: write
jobs:
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    steps:
      - name: Checkout PR
        uses: actions/checkout@v4
      - name: Setup mise
        uses: jdx/mise-action@v2
        with:
          cache: true
      - name: Install dependencies
        run: mise run setup
      - name: Run benchmarks (PR)
        run: |
          echo "Running benchmarks on PR branch..."
          # First check if tests compile
          echo "Checking if tests compile..."
          go test -c ./... || { echo "Compilation failed"; exit 1; }

          # benchtime=100ms: Run each benchmark for 100ms (enough for thousands of iterations)
          # count=3: Run each benchmark 3 times for statistical validity (required by benchstat)
          # 2>&1: Capture both stdout and stderr to see any errors
          echo "Running benchmarks..."
          if ! go test -bench="BenchmarkWrite_|BenchmarkConsumer_" -benchmem -benchtime=100ms -count=3 -run=^$ -timeout=5m > new.bench 2>&1; then
            echo "Benchmark failed! Output:"
            cat new.bench
            exit 1
          fi
          echo "Benchmark results:"
          cat new.bench
      - name: Checkout base branch
        if: github.event_name == 'pull_request'
        run: |
          git fetch origin ${{ github.base_ref }}
          git checkout origin/${{ github.base_ref }}
      - name: Setup mise (base)
        if: github.event_name == 'pull_request'
        uses: jdx/mise-action@v2
        with:
          cache: true
      - name: Run benchmarks (base)
        if: github.event_name == 'pull_request'
        run: |
          # Check if this is a new project (base branch might not have Go code yet)
          if [ ! -f "go.mod" ]; then
            echo "Base branch doesn't have Go code yet, creating dummy benchmark file"
            echo "No benchmarks to compare" > old.bench
          else
            # If no .mise.toml exists, just use go directly
            if [ -f ".mise.toml" ]; then
              mise run setup
            else
              go mod download || true
            fi
            echo "Running benchmarks on base branch..."
            go test -bench="BenchmarkWrite_|BenchmarkConsumer_" -benchmem -benchtime=100ms -count=3 -run=^$ -timeout=5m > old.bench 2>&1
            echo "Base branch benchmark results:"
            cat old.bench
          fi
      - name: Compare benchmarks
        if: github.event_name == 'pull_request'
        run: "# Check if we have valid benchmark files to compare\nif grep -q \"Benchmark\" old.bench 2>/dev/null; then\n  benchstat old.bench new.bench > benchmark-diff.txt\nelse\n  echo \"No base benchmarks to compare against (new project)\" > benchmark-diff.txt\n  echo \"Current benchmark results:\" >> benchmark-diff.txt\n  echo \"\" >> benchmark-diff.txt\n  grep \"Benchmark\" new.bench >> benchmark-diff.txt || echo \"No benchmarks found\"\nfi\n\n# Check for significant regressions with loosened thresholds\n# Rationale: Small performance variations (5-15%) are normal due to:\n#   - CI runner variability\n#   - Memory/CPU allocation differences  \n#   - Background processes\n#   - Minor code changes that don't affect core algorithms\n#\n# Thresholds:\n#   - Latency regression: >20% increase in ns/op, μs/op, ms/op (slower is worse)\n#   - Throughput regression: >10% decrease in ops/sec (lower is worse)\n#\n# Look for latency regressions (20%+ slower)\nif grep -E \"\\\\+[2-9][0-9]\\\\.[0-9]+%|\\\\+[0-9]{3,}\\\\.[0-9]+%\" benchmark-diff.txt | grep -E \"(ns/op|μs/op|ms/op|us/op)\" | grep -v \"~\"; then\n  echo \"::warning::Significant latency regression detected (>20%)\"\n  echo \"REGRESSION_DETECTED=true\" >> $GITHUB_ENV\n# Look for throughput regressions (10%+ slower)\nelif grep -E \"\\\\-[1-9][0-9]\\\\.[0-9]+%|\\\\-[0-9]{2,}\\\\.[0-9]+%\" benchmark-diff.txt | grep -E \"ops/sec\" | grep -v \"~\"; then\n  echo \"::warning::Significant throughput regression detected (>10% decrease)\"\n  echo \"REGRESSION_DETECTED=true\" >> $GITHUB_ENV\nelse\n  echo \"REGRESSION_DETECTED=false\" >> $GITHUB_ENV\nfi\n"
      - name: Comment PR with benchmark results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const diff = fs.readFileSync('benchmark-diff.txt', 'utf8');
            const hasRegression = process.env.REGRESSION_DETECTED === 'true';

            const comment = `## Comet Benchmark Results

            ${hasRegression ? '⚠️ **Significant performance regression detected (>20% latency increase or >10% throughput decrease)**' : '✅ **No significant performance regression detected**'}

            <details>
            <summary>Benchmark comparison</summary>

            \`\`\`
            ${diff}
            \`\`\`
            </details>

            *Benchmarks run on Ubuntu latest with Go ${process.env.MISE_GO_VERSION || '1.24.5'}*`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      - name: Upload benchmark results
        if: github.event_name == 'push'
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-${{ github.sha }}
          path: new.bench
          retention-days: 30
      - name: Fail if regression detected
        if: github.event_name == 'pull_request' && env.REGRESSION_DETECTED == 'true'
        run: |
          echo "Performance regression detected. Please review the benchmark results."
          exit 1
